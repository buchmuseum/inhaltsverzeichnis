{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fertig! Ergebnisse dbsm-treffer.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "from openpyxl import load_workbook\n",
    "import re\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 1) Schlagworte + DDC-Mapping einlesen\n",
    "# ===============================\n",
    "idn_df = pd.read_excel(\"dbsm.xlsx\", dtype=str)\n",
    "\n",
    "# Neue Tabelle mit Schlagwörtern + DDC\n",
    "mapping_df = pd.read_excel(\"schlagworte_ddc_gewichtung.xlsx\", dtype=str)\n",
    "\n",
    "# Schlagwörter separat für Textsuche\n",
    "keywords = mapping_df[mapping_df[\"Typ\"] == \"Schlagwort\"][\"Begriff\"].dropna().tolist()\n",
    "weights = mapping_df.set_index(\"Begriff\")[\"Gewichtung\"].astype(int).to_dict()\n",
    "systematics = mapping_df.set_index(\"Begriff\")[\"Systematik\"].to_dict()\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 2) Volltext durchsuchen\n",
    "# ===============================\n",
    "def find_keywords(idn):\n",
    "    url_text = f\"https://d-nb.info/{idn}/04/text\"\n",
    "    url_pdf = f\"https://d-nb.info/{idn}/04/pdf\"\n",
    "    try:\n",
    "        response = requests.get(url_text, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            text = soup.get_text().lower()\n",
    "\n",
    "            word_counts = {}\n",
    "            for word in keywords:\n",
    "                pattern = re.compile(rf\"\\b\\w*{re.escape(word.lower())}\\w*\\b\", re.IGNORECASE)\n",
    "                matches = pattern.findall(text)\n",
    "                count = len(matches)\n",
    "                if count > 0:\n",
    "                    word_counts[word] = (count, weights.get(word, 1), systematics.get(word, \"\"))\n",
    "\n",
    "            if not word_counts:\n",
    "                return url_text, url_pdf, None, 0, None\n",
    "\n",
    "            total_weight = sum(v[1] for v in word_counts.values())\n",
    "            if len(word_counts) >= 3 or total_weight >= 3:\n",
    "                best_word, (best_count, best_weight, best_syst) = max(\n",
    "                    word_counts.items(),\n",
    "                    key=lambda x: (x[1][1], x[1][0])\n",
    "                )\n",
    "                formatted = \"; \".join(\n",
    "                    f\"{w} (Gewicht={wt}, Treffer={ct})\"\n",
    "                    for w, (ct, wt, _) in word_counts.items()\n",
    "                )\n",
    "                return url_text, url_pdf, formatted, total_weight, best_syst\n",
    "\n",
    "    except requests.RequestException:\n",
    "        return url_text, url_pdf, \"Fehler\", 0, None\n",
    "\n",
    "    return url_text, url_pdf, None, 0, None\n",
    "\n",
    "\n",
    "# Schlagwortsuche anwenden (keine Zeilen löschen!)\n",
    "idn_df[[\"URL\", \"PDF-URL\", \"Gefundene Schlagwörter\", \"Gesamtgewichtung\", \"Gewinner-Systematik\"]] = \\\n",
    "    idn_df.iloc[:, 0].apply(find_keywords).apply(pd.Series)\n",
    "idn_df.rename(columns={idn_df.columns[0]: \"IDN\"}, inplace=True)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 3) SRU-Abfrage inkl. DDC\n",
    "# ===============================\n",
    "def query_dnb(idn):\n",
    "    url = f\"https://services.dnb.de/sru/dnb?version=1.1&operation=searchRetrieve&query=idn={idn}&recordSchema=MARC21plus-xml\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "    root = ET.fromstring(response.text)\n",
    "    ns = {'marc': 'http://www.loc.gov/MARC21/slim'}\n",
    "    title, subtitle, author, publisher, year, ddc = None, None, None, None, None, None\n",
    "\n",
    "    for record in root.findall(\".//marc:record\", ns):\n",
    "        for datafield in record.findall(\"marc:datafield\", ns):\n",
    "            tag = datafield.get(\"tag\")\n",
    "\n",
    "            if tag == \"245\":  # Titel & Zusatztitel\n",
    "                title = datafield.find(\"marc:subfield[@code='a']\", ns)\n",
    "                title = title.text if title is not None else None\n",
    "                subtitle = datafield.find(\"marc:subfield[@code='b']\", ns)\n",
    "                subtitle = subtitle.text if subtitle is not None else None\n",
    "            elif tag == \"100\":  # Autor\n",
    "                author = datafield.find(\"marc:subfield[@code='a']\", ns)\n",
    "                author = author.text if author is not None else None\n",
    "            elif tag in [\"260\", \"264\"]:  # Verlag & Jahr\n",
    "                publisher = datafield.find(\"marc:subfield[@code='b']\", ns)\n",
    "                publisher = publisher.text if publisher is not None else None\n",
    "                year = datafield.find(\"marc:subfield[@code='c']\", ns)\n",
    "                year = year.text if year is not None else None\n",
    "            elif tag in [\"082\", \"083\"]:  # DDC\n",
    "                sub_a = datafield.find(\"marc:subfield[@code='a']\", ns)\n",
    "                if sub_a is not None:\n",
    "                    ddc = sub_a.text\n",
    "\n",
    "    # DBSM prüfen\n",
    "    dbsm_flag = None\n",
    "    for holding in root.findall(\".//marc:record[@type='Holdings']\", ns):\n",
    "        for datafield in holding.findall(\"marc:datafield[@tag='852']\", ns):\n",
    "            sub_b = datafield.find(\"marc:subfield[@code='b']\", ns)\n",
    "            if sub_b is not None and \"dbsm\" in sub_b.text.lower():\n",
    "                dbsm_flag = \"x\"\n",
    "                break\n",
    "\n",
    "    return title, subtitle, author, publisher, year, dbsm_flag, ddc\n",
    "\n",
    "\n",
    "for idx, row in idn_df.iterrows():\n",
    "    title, subtitle, author, publisher, year, dbsm_flag, ddc = query_dnb(row[\"IDN\"])\n",
    "    idn_df.at[idx, \"Titel\"] = title or \"\"\n",
    "    idn_df.at[idx, \"Zusatztitel\"] = subtitle or \"\"\n",
    "    idn_df.at[idx, \"Autor\"] = author or \"\"\n",
    "    idn_df.at[idx, \"Verlag\"] = publisher or \"\"\n",
    "    idn_df.at[idx, \"Jahr\"] = year or \"\"\n",
    "    idn_df.at[idx, \"DBSM-Bestand\"] = dbsm_flag or \"\"\n",
    "    idn_df.at[idx, \"DDC\"] = ddc or \"\"\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 4) Schlagwort- und DDC-Mapping\n",
    "# ===============================\n",
    "def apply_mapping(row):\n",
    "    total_weight = row[\"Gesamtgewichtung\"] if pd.notna(row[\"Gesamtgewichtung\"]) else 0\n",
    "    systematik = row[\"Gewinner-Systematik\"]\n",
    "    found_extra = []\n",
    "\n",
    "    # Titel + Zusatztitel durchsuchen (falls vorhanden)\n",
    "    for text in [row.get(\"Titel\"), row.get(\"Zusatztitel\")]:\n",
    "        if pd.notna(text):\n",
    "            t = text.lower()\n",
    "            for w in keywords:\n",
    "                if re.search(rf\"\\b{re.escape(w.lower())}\\b\", t):\n",
    "                    total_weight += weights.get(w, 1)\n",
    "                    found_extra.append(w)\n",
    "                    if not systematik:\n",
    "                        systematik = systematics.get(w)\n",
    "\n",
    "    # DDC prüfen\n",
    "    if pd.notna(row.get(\"DDC\")):\n",
    "        for ddc_code in str(row[\"DDC\"]).split(\";\"):\n",
    "            ddc_code = ddc_code.strip()\n",
    "            if not ddc_code:\n",
    "                continue\n",
    "            if ddc_code in systematics:\n",
    "                systematik = systematics[ddc_code]\n",
    "                found_extra.append(f\"DDC {ddc_code}\")\n",
    "            for key in systematics.keys():\n",
    "                if key.startswith(f\"{ddc_code} +\"):\n",
    "                    systematik = systematics[key]\n",
    "                    found_extra.append(key)\n",
    "\n",
    "    return pd.Series([total_weight, systematik, \"; \".join(found_extra)])\n",
    "\n",
    "\n",
    "idn_df[[\"Gesamtgewichtung\", \"Gewinner-Systematik\", \"Zusätzliche Treffer\"]] = \\\n",
    "    idn_df.apply(apply_mapping, axis=1)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 5) KEIN Filtern mehr!\n",
    "# ===============================\n",
    "# Alle IDNs bleiben erhalten, auch ohne Treffer\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 6) Excel speichern + Hyperlinks\n",
    "# ===============================\n",
    "output_file = \"dbsm-treffer.xlsx\"\n",
    "idn_df.to_excel(output_file, index=False)\n",
    "\n",
    "wb = load_workbook(output_file)\n",
    "ws = wb.active\n",
    "col_url = [c[0] for c in enumerate(ws[1]) if c[1].value == \"URL\"][0] + 1\n",
    "col_pdf = [c[0] for c in enumerate(ws[1]) if c[1].value == \"PDF-URL\"][0] + 1\n",
    "\n",
    "for row in range(2, ws.max_row + 1):\n",
    "    if ws.cell(row=row, column=col_url).value:\n",
    "        ws.cell(row=row, column=col_url).hyperlink = ws.cell(row=row, column=col_url).value\n",
    "        ws.cell(row=row, column=col_url).style = \"Hyperlink\"\n",
    "    if ws.cell(row=row, column=col_pdf).value:\n",
    "        ws.cell(row=row, column=col_pdf).hyperlink = ws.cell(row=row, column=col_pdf).value\n",
    "        ws.cell(row=row, column=col_pdf).style = \"Hyperlink\"\n",
    "\n",
    "wb.save(output_file)\n",
    "print(\"Fertig! Ergebnisse dbsm-treffer.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
