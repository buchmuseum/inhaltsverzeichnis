{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fertig! Datei 'gefilterte_saetze.xlsx' erstellt ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# ---------- Hilfsfunktion: Encoding-Reparatur ----------\n",
    "def fix_mojibake_text(s):\n",
    "    \"\"\"\n",
    "    Repariert häufige UTF-8/CP1252-Mojibake (z.B. 'ErschlieÃŸung', 'prekaÌˆrer')\n",
    "    und normalisiert anschließend zu NFC (z.B. 'ä' -> 'ä').\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    # Versuch: als CP1252 Bytes interpretieren und korrekt als UTF-8 dekodieren\n",
    "    try:\n",
    "        s_fixed = s.encode(\"cp1252\").decode(\"utf-8\")\n",
    "    except Exception:\n",
    "        s_fixed = s\n",
    "    # Unicode-Normalisierung (z.B. a +  ̈ -> ä)\n",
    "    s_fixed = unicodedata.normalize(\"NFC\", s_fixed)\n",
    "    return s_fixed\n",
    "\n",
    "def fix_mojibake_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.applymap(fix_mojibake_text)\n",
    "\n",
    "# Schlagwort-Datei laden (mit Spalten: Schlagwort, Gewicht, Systematik, Alleinstehend)\n",
    "schlagworte_df = pd.read_excel(\"schlagworte_gewichtung.xlsx\")\n",
    "schlagworte_df.columns = schlagworte_df.columns.str.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Dictionaries für schnelleren Zugriff\n",
    "weights = dict(zip(schlagworte_df[\"Schlagwort\"], schlagworte_df[\"Gewichtung\"]))\n",
    "systematics = dict(zip(schlagworte_df[\"Schlagwort\"], schlagworte_df[\"Systematik\"]))\n",
    "\n",
    "\n",
    "# O-Sätze laden\n",
    "saetze_df = pd.read_excel(\"o.xlsx\")\n",
    "saetze_df.columns = saetze_df.columns.str.strip()\n",
    "# Encoding-Fix auf die O-Sätze anwenden\n",
    "saetze_df = fix_mojibake_df(saetze_df)\n",
    "\n",
    "# ---------- DDC-Blacklist ----------\n",
    "blacklist_ddc = [\n",
    "    \"360\", \"590\", \"910\", \"333\", \"355\", \"370\",\n",
    "    \"510\", \"610\", \"621\", \"690\", \"796\", \"797\", \"798\", \"799\", \"914\", \"K\"\n",
    "]\n",
    "if \"DDC\" in saetze_df.columns:\n",
    "    saetze_df = saetze_df[~saetze_df[\"DDC\"].astype(str).str.startswith(tuple(blacklist_ddc), na=False)]\n",
    "\n",
    "# Alle Spalten außer \"IDN\" durchsuchen\n",
    "spalten_zum_pruefen = [col for col in saetze_df.columns if col != \"IDN\"]\n",
    "\n",
    "def evaluate_row(row):\n",
    "    text_all = \" \".join(str(val) for val in row if not pd.isna(val)).lower()\n",
    "    word_counts = {}\n",
    "\n",
    "    for word in weights.keys():\n",
    "        count = text_all.count(word.lower())\n",
    "        if count > 0:\n",
    "            gewicht = weights.get(word, 1)\n",
    "            score = count * gewicht\n",
    "            word_counts[word] = (count, score, systematics.get(word, \"\"))\n",
    "\n",
    "    if not word_counts:\n",
    "        return 0, \"\", 0, \"\"\n",
    "\n",
    "    total_weight = sum(weights.get(w, 1) for w in word_counts.keys())\n",
    "\n",
    "    # Entscheidungskriterien\n",
    "    if len(word_counts) >= 3 or total_weight >= 3:\n",
    "        formatted = [\n",
    "            f\"{word} ({count} Treffer, Gewicht={weights.get(word,1)}, Score={score}, Systematik={syst})\"\n",
    "            for word, (count, score, syst) in word_counts.items()\n",
    "        ]\n",
    "        return len(word_counts), \"; \".join(formatted), total_weight, \"OK\"\n",
    "\n",
    "\n",
    "\n",
    "# Neue Spalten erzeugen\n",
    "saetze_df[[\"Count\", \"Gefundene_Schlagworte\", \"Gesamtgewichtung\", \"Status\"]] = saetze_df[spalten_zum_pruefen].apply(\n",
    "    lambda row: pd.Series(evaluate_row(row)), axis=1\n",
    ")\n",
    "\n",
    "# Nur Zeilen mit Status=OK übernehmen\n",
    "ergebnis_df = saetze_df[saetze_df[\"Status\"] == \"OK\"][[\"IDN\", \"Titel\",\"Zusatztitel\", \"DDC\", \"Count\", \"Gesamtgewichtung\", \"Gefundene_Schlagworte\"]]\n",
    "\n",
    "# --- Zeilen mit \"Roman\" im Titel oder Zusatztitel löschen ---\n",
    "for col in [\"Titel\", \"Zusatztitel\"]:\n",
    "    if col in ergebnis_df.columns:\n",
    "        ergebnis_df = ergebnis_df[~ergebnis_df[col].str.contains(r\"\\broman\\b\", case=False, na=False)]\n",
    "\n",
    "\n",
    "# Ergebnis speichern\n",
    "ergebnis_df.to_excel(\"neu_gefilterte_saetze.xlsx\", index=False)\n",
    "\n",
    "print(\"Fertig! Datei 'gefilterte_saetze.xlsx' erstellt ✅\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
